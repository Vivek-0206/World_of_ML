{
  
    
        "post0": {
            "title": "Start write blog",
            "content": "Start write blog within 10 min . How to start write blog direct from markdown and through Jupyter notebook with . . Requirement . github account. | . Follow step . Use fastai/fastpages template. Within 20-30 sec one pull request is generated by github-action. | Follow step and create SSH key from this and add public and private key. | After that merge pull request and wait for 2-3 min for github-action to build the site. | Change Name and description . open _config.yml in edit mode. | change name and description | also you can edit social links(optional) | . . . . Adding stuff . Make sure are you add stuff into direct master OR main branch. | You can add notebook, word and markdown file into _notebook , _posts and _word folder according to. | You can upload images as wall in images folder | . . . .",
            "url": "https://vivek2509.github.io/World_of_ML/markdown/2020/10/18/How-to-start-blog-from-fastpage.html",
            "relUrl": "/markdown/2020/10/18/How-to-start-blog-from-fastpage.html",
            "date": " ‚Ä¢ Oct 18, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Email Spam Detector",
            "content": "Import library . import pandas as pd import numpy as np import matplotlib.pyplot as plt . Import dataset . email = pd.read_csv(&#39;emails.csv&#39;) . email.head(10) . text spam . 0 Subject: naturally irresistible your corporate... | 1 | . 1 Subject: the stock trading gunslinger fanny i... | 1 | . 2 Subject: unbelievable new homes made easy im ... | 1 | . 3 Subject: 4 color printing special request add... | 1 | . 4 Subject: do not have money , get software cds ... | 1 | . 5 Subject: great nnews hello , welcome to medzo... | 1 | . 6 Subject: here &#39; s a hot play in motion homela... | 1 | . 7 Subject: save your money buy getting this thin... | 1 | . 8 Subject: undeliverable : home based business f... | 1 | . 9 Subject: save your money buy getting this thin... | 1 | . len(email) . 5728 . email.isna().sum() . text 0 spam 0 dtype: int64 . email.shape . (5728, 2) . email.tail() . text spam . 5723 Subject: re : research and development charges... | 0 | . 5724 Subject: re : receipts from visit jim , than... | 0 | . 5725 Subject: re : enron case study update wow ! a... | 0 | . 5726 Subject: re : interest david , please , call... | 0 | . 5727 Subject: news : aurora 5 . 2 update aurora ve... | 0 | . Cleaning the text . import re import nltk nltk.download(&#39;stopwords&#39;) from nltk.corpus import stopwords from nltk.stem.porter import PorterStemmer corpus = [] for i in range(0, len(email)): e_mail = re.sub(&#39;[^a-zA-Z]&#39;, &#39; &#39;, email[&#39;text&#39;][i]) e_mail = e_mail.split() ps = PorterStemmer() e_mail = [ps.stem(word) for word in e_mail if not word in set(stopwords.words(&#39;english&#39;))] e_mail = &#39; &#39;.join(e_mail) corpus.append(e_mail) . [nltk_data] Downloading package stopwords to [nltk_data] C: Users patel AppData Roaming nltk_data... [nltk_data] Package stopwords is already up-to-date! . corpus[2509] . &#39;subject enron mid year perform manag process enron mid year perform manag process begun process requir select suggest review provid perform relat feedback may also request provid feedback fellow employe need access perform manag system pep http pep enron com question direct pep help desk follow number u option europ option canada canada employe e mail question perfmgmt enron com log pep enter user id password provid log immedi prompt chang secur password user id password user id wkamin password welcom&#39; . Creating the Bag of Words model . from sklearn.feature_extraction.text import CountVectorizer cv = CountVectorizer() X = cv.fit_transform(corpus).toarray() y = email[&#39;spam&#39;] . len(X) . 5728 . X.shape . (5728, 25607) . len(y) . 5728 . Splitting the dataset into the Training set and Test set . from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0) . Training the Naive Bayes model on the Training set . 1.GaussianNB . from sklearn.naive_bayes import GaussianNB GN_classifier = GaussianNB() GN_classifier.fit(X_train, y_train) . GaussianNB() . GN_score = GN_classifier.score(X_test,y_test) GN_score . 0.9607329842931938 . y_GN_pred = GN_classifier.predict(X_test) . y_GN_pred . array([0, 0, 1, ..., 0, 0, 1], dtype=int64) . 2.MultinomialNB . from sklearn.naive_bayes import MultinomialNB MN_classifier = MultinomialNB() MN_classifier.fit(X_train, y_train) . MultinomialNB() . MN_score = MN_classifier.score(X_test,y_test) MN_score . 0.9825479930191972 . y_MN_pred = MN_classifier.predict(X_test) . Making the Confusion Matrix . from sklearn.metrics import confusion_matrix GN_cm = confusion_matrix(y_test, y_GN_pred) print(GN_cm) . [[875 10] [ 35 226]] . from sklearn.metrics import confusion_matrix MN_cm = confusion_matrix(y_test, y_MN_pred) print(MN_cm) . [[870 15] [ 5 256]] . Compare Both models . models = pd.DataFrame({&quot;GaussianNB&quot;: GN_score, &quot;MultinomialNB&quot;: MN_score }, index=[0]) models.T.plot.bar(title=&quot;Comapre different models&quot;, legend=False) plt.xticks(rotation=0); . SAVE MODEL . import pickle pickle.dump(MN_classifier,open(&quot;Email_spam_naive_bayes_MN.pkl&quot;,&quot;wb&quot;)) .",
            "url": "https://vivek2509.github.io/World_of_ML/jupyter/2020/10/10/Email_spam.html",
            "relUrl": "/jupyter/2020/10/10/Email_spam.html",
            "date": " ‚Ä¢ Oct 10, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". AI/ML enthusiast with ‚ô• in photography üì∏. .",
          "url": "https://vivek2509.github.io/World_of_ML/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://vivek2509.github.io/World_of_ML/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}